{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edfd1ebf",
   "metadata": {},
   "source": [
    "# IN3063 - Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66e90e",
   "metadata": {},
   "source": [
    "### Team members:\n",
    "1. Aymen \n",
    "2. Philip\n",
    "3. Adam\n",
    "4. Taha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da372ae8",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "723a7cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0f9e5",
   "metadata": {},
   "source": [
    "## Sigmoid & ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412fa30c",
   "metadata": {},
   "source": [
    "- By Aymen\n",
    "- Reference:\n",
    "    - https://towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795\n",
    "    - https://www.sharpsightlabs.com/blog/numpy-relu/\n",
    "    - Lab 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed98cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for Sigmoid\n",
    "def forward_sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Backward pass for Sigmoid\n",
    "def backward_sigmoid(x):\n",
    "    return forward_sigmoid(x) * (1 - forward_sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed656454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for ReLU\n",
    "def forward_relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Backward pass for ReLU\n",
    "def backward_relu(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f493982",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febca3b9",
   "metadata": {},
   "source": [
    "- By Aymen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f1466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31dd9266",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66744b60",
   "metadata": {},
   "source": [
    "- By Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout():\n",
    "    pass # placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f38de",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "- By Philip  \n",
    "Implement a fully parametrizable neural network class\n",
    "You should implement a fully-connected NN class where with number of\n",
    "hidden layers, units, activation functions can be changed. In addition, you\n",
    "can add dropout or regularizer (L1 or L2). Report the parameters used\n",
    "(update rule, learning rate, decay, epochs, batch size) and include the plots\n",
    "in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bccdc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the MNIST dataset as per http://yann.lecun.com/exdb/mnist/\n",
    "import os\n",
    "import struct\n",
    "\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        # Read two bytes (big endian and unsigned)\n",
    "        zero, data_type, dims = struct.unpack('>HBB', file.read(4))\n",
    "        # Four byte integer big endian\n",
    "        shape = tuple(struct.unpack('>I', file.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(file.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "def load_mnist(path):\n",
    "    # Paths to the files\n",
    "    train_images_path = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "    train_labels_path = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    test_images_path = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "    test_labels_path = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "\n",
    "    # Loading the datasets\n",
    "    train_images = read_idx(train_images_path)\n",
    "    train_labels = read_idx(train_labels_path)\n",
    "    test_images = read_idx(test_images_path)\n",
    "    test_labels = read_idx(test_labels_path)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ccca774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example use\n",
    "t_images, t_labels, test_images, test_labels = load_mnist('./dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe77577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self, activation_function, layers, batch_size, neurons):\n",
    "        \"\"\"\n",
    "        Initialises a new instance of the NeuralNet class.\n",
    "\n",
    "        Parameters:\n",
    "        activation_function (function): The activation function to be used in the network layers. \n",
    "                                        The function is used in all layers. \n",
    "        layers (int): The number of layers in the neural network.\n",
    "        batch_size (int): The size of the batches used in training. This affects how the data is split during training iterations.\n",
    "        neurons (list of int): The number of neurons in each layer. This should be a list where each element represents \n",
    "                               the number of neurons in the respective layer of the network.\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        self.activation_function = activation_function\n",
    "        self.layers = layers\n",
    "        self.batch_size = batch_size\n",
    "        self.neurons = neurons\n",
    "        # Will be initialised once features are known\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "\n",
    "    def init_weights_and_biases(self, input_features):\n",
    "        # Initialize weights and biases based on the layers, neurons, and input features\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        for i in range(self.layers):\n",
    "            if i == 0:\n",
    "                layer_weights = np.random.randn(self.neurons[i], input_features) * 0.01\n",
    "            else:\n",
    "                layer_weights = np.random.randn(self.neurons[i], self.neurons[i - 1]) * 0.01\n",
    "            layer_bias = np.zeros((self.neurons[i], 1))\n",
    "            self.weights.append(layer_weights)\n",
    "            self.biases.append(layer_bias)\n",
    "\n",
    "    def train_network(self, optimizer, loss_function, epochs, batch_size, X_train, Y_train):\n",
    "        pass\n",
    "    \n",
    "    def evaluate_model(self, x_test, y_test, X_train, Y_train, loss_list):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c8821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
