{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CrzPhil/IN3063-Coursework/blob/main/Coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edfd1ebf",
      "metadata": {
        "id": "edfd1ebf"
      },
      "source": [
        "# IN3063 - Coursework"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c66e90e",
      "metadata": {
        "id": "4c66e90e"
      },
      "source": [
        "### Team members:\n",
        "1. Aymen\n",
        "2. Philip\n",
        "3. Adam\n",
        "4. Taha"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da372ae8",
      "metadata": {
        "id": "da372ae8"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "723a7cf4",
      "metadata": {
        "id": "723a7cf4"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb0f9e5",
      "metadata": {
        "id": "8cb0f9e5"
      },
      "source": [
        "## Sigmoid & ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "412fa30c",
      "metadata": {
        "id": "412fa30c"
      },
      "source": [
        "- By Aymen\n",
        "- Reference:\n",
        "    - https://towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795\n",
        "    - https://www.sharpsightlabs.com/blog/numpy-relu/\n",
        "    - Lab 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed98cad4",
      "metadata": {
        "id": "ed98cad4"
      },
      "outputs": [],
      "source": [
        "# Forward pass for Sigmoid\n",
        "def forward_sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Backward pass for Sigmoid\n",
        "def backward_sigmoid(x):\n",
        "    return forward_sigmoid(x) * (1 - forward_sigmoid(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed656454",
      "metadata": {
        "id": "ed656454"
      },
      "outputs": [],
      "source": [
        "# Forward pass for ReLU\n",
        "def forward_relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# Backward pass for ReLU\n",
        "def backward_relu(x):\n",
        "    return np.where(x > 0, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f493982",
      "metadata": {
        "id": "7f493982"
      },
      "source": [
        "## Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "febca3b9",
      "metadata": {
        "id": "febca3b9"
      },
      "source": [
        "- By Aymen\n",
        "- Using the Numpy version\n",
        "- Reference:\n",
        "    - https://towardsdatascience.com/softmax-function-simplified-714068bf8156\n",
        "    - https://en.wikipedia.org/wiki/Softmax_function\n",
        "    - https://www.sharpsightlabs.com/blog/numpy-softmax/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c0f1466",
      "metadata": {
        "id": "6c0f1466",
        "outputId": "3a97035f-7f0f-454f-9b2a-57ced3cdecf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forward pass result: [0. 1. 0.]\n",
            "Backward pass result: [[0. 0. 0.]]\n",
            "\n",
            "\n",
            "Forward pass result: [0.09003057 0.24472847 0.66524096]\n",
            "Backward pass result: [[0.08192507 0.18483645 0.22269543]]\n"
          ]
        }
      ],
      "source": [
        "# Forward pass for Softmax\n",
        "def forward_softmax(x):\n",
        "    exponential = np.exp(x - np.max(x))\n",
        "    return exponential / exponential.sum() # calculates softmax probability\n",
        "\n",
        "# Backward pass for Softmax\n",
        "def backward_softmax(x):\n",
        "    return np.reshape(forward_softmax(x) * (1 - forward_softmax(x)), (1, -1)) # computes gradient of softmax\n",
        "\n",
        "# Testing:\n",
        "x = np.array([100.0, 2000.0, 300.0]) # large numbers\n",
        "print(\"Forward pass result:\", forward_softmax(x))\n",
        "print(\"Backward pass result:\", backward_softmax(x))\n",
        "print (\"\\n\")\n",
        "\n",
        "x = np.array([1.0, 2.0, 3.0]) # small numbers\n",
        "print(\"Forward pass result:\", forward_softmax(x))\n",
        "print(\"Backward pass result:\", backward_softmax(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31dd9266",
      "metadata": {
        "id": "31dd9266"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66744b60",
      "metadata": {
        "id": "66744b60"
      },
      "source": [
        "- By Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3955086a",
      "metadata": {
        "id": "3955086a"
      },
      "outputs": [],
      "source": [
        "def dropout():\n",
        "    pass # placeholder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "875f38de",
      "metadata": {
        "id": "875f38de"
      },
      "source": [
        "## Neural Network\n",
        "- By Philip  \n",
        "Implement a fully parametrizable neural network class\n",
        "You should implement a fully-connected NN class where with number of\n",
        "hidden layers, units, activation functions can be changed. In addition, you\n",
        "can add dropout or regularizer (L1 or L2). Report the parameters used\n",
        "(update rule, learning rate, decay, epochs, batch size) and include the plots\n",
        "in your report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bccdc1a",
      "metadata": {
        "id": "3bccdc1a"
      },
      "outputs": [],
      "source": [
        "# Reading the MNIST dataset as per http://yann.lecun.com/exdb/mnist/\n",
        "import os\n",
        "import struct\n",
        "\n",
        "def read_idx(filename):\n",
        "    with open(filename, 'rb') as file:\n",
        "        # Read two bytes (big endian and unsigned)\n",
        "        zero, data_type, dims = struct.unpack('>HBB', file.read(4))\n",
        "        # Four byte integer big endian\n",
        "        shape = tuple(struct.unpack('>I', file.read(4))[0] for d in range(dims))\n",
        "        return np.frombuffer(file.read(), dtype=np.uint8).reshape(shape)\n",
        "\n",
        "def load_mnist(path):\n",
        "    # Paths to the files\n",
        "    train_images_path = os.path.join(path, 'train-images-idx3-ubyte')\n",
        "    train_labels_path = os.path.join(path, 'train-labels-idx1-ubyte')\n",
        "    test_images_path = os.path.join(path, 't10k-images-idx3-ubyte')\n",
        "    test_labels_path = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
        "\n",
        "    # Loading the datasets\n",
        "    train_images = read_idx(train_images_path)\n",
        "    train_labels = read_idx(train_labels_path)\n",
        "    test_images = read_idx(test_images_path)\n",
        "    test_labels = read_idx(test_labels_path)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccca774e",
      "metadata": {
        "id": "ccca774e",
        "outputId": "1d568245-7f34-46b8-f2c5-63ff8857b883"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example use\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m t_images, t_labels, test_images, test_labels \u001b[38;5;241m=\u001b[39m load_mnist(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[1], line 21\u001b[0m, in \u001b[0;36mload_mnist\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     18\u001b[0m test_labels_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt10k-labels-idx1-ubyte\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Loading the datasets\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m train_images \u001b[38;5;241m=\u001b[39m read_idx(train_images_path)\n\u001b[1;32m     22\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m read_idx(train_labels_path)\n\u001b[1;32m     23\u001b[0m test_images \u001b[38;5;241m=\u001b[39m read_idx(test_images_path)\n",
            "Cell \u001b[0;32mIn[1], line 11\u001b[0m, in \u001b[0;36mread_idx\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Four byte integer big endian\u001b[39;00m\n\u001b[1;32m     10\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>I\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dims))\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mfrombuffer(file\u001b[38;5;241m.\u001b[39mread(), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mreshape(shape)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "# Example use\n",
        "t_images, t_labels, test_images, test_labels = load_mnist('./dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe77577b",
      "metadata": {
        "id": "fe77577b"
      },
      "outputs": [],
      "source": [
        "class NeuralNet:\n",
        "    def __init__(self, activation_function, layers, batch_size, neurons):\n",
        "        \"\"\"\n",
        "        Initialises a new instance of the NeuralNet class.\n",
        "\n",
        "        Parameters:\n",
        "        activation_function (function): The activation function to be used in the network layers.\n",
        "                                        The function is used in all layers.\n",
        "        layers (int): The number of layers in the neural network.\n",
        "        batch_size (int): The size of the batches used in training. This affects how the data is split during training iterations.\n",
        "        neurons (list of int): The number of neurons in each layer. This should be a list where each element represents\n",
        "                               the number of neurons in the respective layer of the network.\n",
        "        Returns:\n",
        "        None\n",
        "        \"\"\"\n",
        "        self.activation_function = activation_function\n",
        "        self.layers = layers\n",
        "        self.batch_size = batch_size\n",
        "        self.neurons = neurons\n",
        "        # Will be initialised once features are known\n",
        "        self.weights = None\n",
        "        self.biases = None\n",
        "\n",
        "    def init_weights_and_biases(self, input_features):\n",
        "        # Initialize weights and biases based on the layers, neurons, and input features\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "\n",
        "        for i in range(self.layers):\n",
        "            if i == 0:\n",
        "                layer_weights = np.random.randn(self.neurons[i], input_features) * 0.01\n",
        "            else:\n",
        "                layer_weights = np.random.randn(self.neurons[i], self.neurons[i - 1]) * 0.01\n",
        "            layer_bias = np.zeros((self.neurons[i], 1))\n",
        "            self.weights.append(layer_weights)\n",
        "            self.biases.append(layer_bias)\n",
        "\n",
        "    def train_network(self, optimizer, loss_function, epochs, batch_size, X_train, Y_train):\n",
        "        pass\n",
        "\n",
        "    def evaluate_model(self, x_test, y_test, X_train, Y_train, loss_list):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd9c8821",
      "metadata": {
        "id": "fd9c8821"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}